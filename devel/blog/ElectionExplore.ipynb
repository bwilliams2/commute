{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supreme-modern",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import geopandas as gpd\n",
    "matplotlib.rcParams['figure.figsize'] = (15, 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-awareness",
   "metadata": {},
   "source": [
    "# Loading Data from Postgis Database\n",
    "\n",
    "The data has already been loaded in to a Postgres database with the [Postgis](https://postgis.net/) extension to allow for geometric manipulations (covered in a previous post LINK).\n",
    "I mostly just want all of the table data to begin with. \n",
    "I could probably parse down what I am getting here based on location but it doesn't make a whole lot of difference right now.\n",
    "\n",
    "For the election precincts, I am adding the distance to representative latitude and longitude positions for Minneapolis and St. Paul as a lazy proxy for \"suburban\" and \"urban\" definitions to see if these are important considerations.\n",
    "This is something that will probably need to be revisited later.\n",
    "Postgis makes this very simple and uses a spheroid calculation with the 4326 projection.\n",
    "\n",
    "To calculate the distance from St. Paul to a given geometry, I use the `ST_Distance` function from Postgis which finds the geodesic distance between the provided point for St. Paul and the `geom_c` column of the election table which was calculated during database population.\n",
    "The `ST_Distance` function uses a spheroid distance caluclation when `geography` types are specified.\n",
    "\n",
    "```\n",
    "ST_Distance('SRID=4326;POINT(-93.2650 -44.9537)'::geography, e.geom_c)\n",
    "```\n",
    "\n",
    "From the database, I pull the precinct data mentioned above, census data, and property parcel data.\n",
    "The precinct and census data cover all of Minnesota while the parcel information is only the Twin Cities metro counties.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neutral-figure",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2  # (if it is postgres/postgis)\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"../../.env\")\n",
    "con = psycopg2.connect(database=\"postgres\", user=\"postgres\", password=os.getenv(\"POSTGRES_PASSWORD\"), host=\"localhost\")\n",
    "\n",
    "stpaul = \"-93.0900 -44.9537\"\n",
    "minneapolis = \"-93.2650 44.9778\"\n",
    "sql = f\"select *, ST_Distance('SRID=4326;POINT({stpaul})'::geography, e.geom_c) as stp_dis, ST_Distance('SRID=4326;POINT({minneapolis})'::geography, e.geom_c) as mpls_dis from election e\"\n",
    "election_data = gpd.read_postgis(sql, con)\n",
    "sql = f\"select * from census\"\n",
    "census_data = gpd.read_postgis(sql, con)\n",
    "sql = f\"select * from parcels\"\n",
    "org_parcel_data = gpd.read_postgis(sql, con)\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "devoted-element",
   "metadata": {},
   "source": [
    "There are a couple of quick data cleaning items for the election data I want to do off the bat.\n",
    "\n",
    "    - Correct the mis-labeled `vtd` column and merge with `vtdid` for the year 2012\n",
    "    - Convert calculated distance from city centers from meters to miles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-camping",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2012 uses a \"vtd\" column while every other year uses \"vtdid\" so quick fix for that \n",
    "election_data[\"vtdid\"] = election_data[\"vtdid\"].fillna(election_data[\"vtd\"]).drop(columns=\"vtd\")\n",
    "# Add city_dis column\n",
    "election_data[\"cit_dis\"] = election_data[[\"stp_dis\", \"mpls_dis\"]].min(axis=1)/1609.344 # meters to miles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tight-alignment",
   "metadata": {},
   "source": [
    "# Defining Precinct Parcel Characteristics\n",
    "\n",
    "There are "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-florist",
   "metadata": {},
   "source": [
    "For now, I want to look at only \"single-family residental\" parcels.\n",
    "Analysis could be done with additional residental parcel categories, but there is a lot of missing info on the size of the buildings with condomimums and apartments that make it difficult to accurately analyze with these included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lonely-cornell",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_family = [\"100 Res 1 unit\", \"Res 1 unit\", \"100 Res 1 Unit\", \"Residential\", \"RESIDENTIAL SINGLE FAMILY\", 'RESIDENTIAL', 'Residential Lakeshore']\n",
    "res_mask = org_parcel_data[\"useclass1\"].isin(single_family)\n",
    "parcel_data = org_parcel_data.loc[res_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "involved-scenario",
   "metadata": {},
   "source": [
    "Additionally, limiting the information used from the parcels to total estimated value (`emv_total`), year built (`year_built`), and last sale date (`sale_date`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abstract-latvia",
   "metadata": {},
   "source": [
    "# Get Precinct Statistics\n",
    "\n",
    "The parcel data is tagged by precinct for each year that geographic parcel information was available under columns coded as `vtdid_{YEAR}`.\n",
    "This"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "homeless-astrology",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"emv_total\", \"year_built\", \"sale_date\"] + [col for col in parcel_data.columns if \"vtd\" in col]\n",
    "parcel_data = parcel_data.loc[:, cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "owned-drinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "vtd_cols = [col for col in parcel_data.columns if \"vtd\" in col]\n",
    "id_cols = [col for col in parcel_data.columns if \"vtd\" not in col]\n",
    "pivot_data = parcel_data.melt(id_vars=id_cols, value_vars = vtd_cols, var_name=\"year\", value_name=\"vtdid\")\n",
    "pivot_data[\"year\"] = pivot_data[\"year\"].str.strip(\"vtdid_\").astype(np.int)\n",
    "pivot_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confident-planner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_precinct_stats(df):\n",
    "    df = df.loc[df[\"year\"] != 0 & df[\"year\"].notna()]\n",
    "    median_tax = df[\"emv_total\"].loc[df[\"emv_total\"] > 0].median()\n",
    "    mean_tax = df[\"emv_total\"].loc[df[\"emv_total\"] > 0].mean()\n",
    "    house_age = df.loc[:, \"year_built\"].loc[df[\"year_built\"] > 0].median()\n",
    "    mean_age = df.loc[:, \"year_built\"].loc[df[\"year_built\"] > 0].mean()\n",
    "    five_year_growth = (df.loc[df[\"year_built\"] >= 2015].shape[0])/df.shape[0]\n",
    "    return pd.Series({\"median_emv\": median_tax, \"mean_emv\": mean_tax, \"median_age\": house_age, \"mean_age\": mean_age, \"growth\": five_year_growth})\n",
    "\n",
    "processed = pivot_data.groupby([\"year\", \"vtdid\"]).apply(create_precinct_stats).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-corpus",
   "metadata": {},
   "outputs": [],
   "source": [
    "election_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varying-directive",
   "metadata": {},
   "outputs": [],
   "source": [
    "counties = [\"Anoka\", \"Dakota\", \"Hennepin\", \"Scott\", \"Ramsey\", \"Washington\", \"Carver\"]\n",
    "metro_mask = election_data[\"countyname\"].isin(counties)\n",
    "election_data.loc[metro_mask & (election_data.year == 2020)].plot(column=\"usprsdfl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternate-singing",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_election = election_data.merge(processed, on=[\"year\", \"vtdid\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informative-sucking",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_election.loc[merged_election.countyname.isin(counties)].plot(column=\"usprsdfl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-tournament",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpd.GeoDataFrame(merged_election, geometry=\"geom\").plot(column=\"usprstotal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trained-video",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_margins(df):\n",
    "    vote_cols = [col for col in merged_election.columns if \"dfl\" in col]\n",
    "    for col in vote_cols:\n",
    "        base = col.replace(\"dfl\", \"\")\n",
    "        df[base+\"_margin\"] = (df[base+\"dfl\"].values - df[base+\"r\"].values)/df[base+\"total\"].values * 100\n",
    "        df[base+\"_vote_density\"] = df[base+\"total\"]/df[\"parcel_area\"]\n",
    "    return df\n",
    "margins_election1 = calc_margins(merged_election)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "activated-thanks",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpd.GeoDataFrame(margins_election1.loc[(margins_election1.year == 2020) ], geometry=\"geom\").plot(column=\"usprs_margin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convenient-terrorism",
   "metadata": {},
   "source": [
    "# Add Census Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joint-payment",
   "metadata": {},
   "outputs": [],
   "source": [
    "census_data[\"popdensity\"] = census_data[\"totpop\"]/census_data[\"tract_area\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mexican-labor",
   "metadata": {},
   "outputs": [],
   "source": [
    "margins_election = margins_election1.merge(census_data.drop(columns=[\"id\", \"year\", \"tract_area\", \"geom\", \"geom_c\"]), left_on=\"tract_geoid\", right_on=\"geoid\")\n",
    "gmargins_election = gpd.GeoDataFrame(margins_election, geometry=\"geom\")\n",
    "gmargins_election.loc[(margins_election.year == 2020) & (margins_election[\"countyname\"].isin(counties))].plot(column=\"ronehouse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "according-birth",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmargins_election.loc[(margins_election.year == 2020) & (margins_election[\"countyname\"].isin(counties))].plot(column=\"medinc\", legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "isolated-bouquet",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmargins_election.loc[(margins_election.year == 2020) & (margins_election[\"countyname\"].isin(counties))].plot(column=\"medage\", legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designed-thumbnail",
   "metadata": {},
   "source": [
    "# Convert vtdid\n",
    "The VTDID numbering is not continuous.\n",
    "For exploration purposes I want to switch this to a continguous index.\n",
    "I aleady merged the data I need using VTDID so this isn't a problem to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charitable-belle",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(margins_election[\"vtdid\"].sort_values().astype(np.int).unique())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comfortable-fishing",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# margins_election[\"vtdid\"] = margins_election[\"vtdid\"].astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ready-schedule",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(margins_election[\"vtdid\"].sort_values().unique())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-rochester",
   "metadata": {},
   "source": [
    "# Presidential Data\n",
    "I will focus on the three presidential datasets included in the parcel election results from 2012, 2016, and 2020.\n",
    "The"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fiscal-boating",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [2012, 2016, 2020]\n",
    "pres_data = margins_election.loc[margins_election.year.isin(years)]\n",
    "fig, ax = plt.subplots(1, 2, figsize=[25,10])\n",
    "ax[0].plot(years, pres_data.groupby(\"year\")[\"usprstotal\"].sum(), \"--o\")\n",
    "ax[0].set_xlabel(\"year\")\n",
    "ax[0].set_ylabel(\"usprstotal\")\n",
    "sns.scatterplot(data=pres_data, x=\"vtdid\", y=\"usprstotal\", hue=\"year\",ax=ax[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gross-floating",
   "metadata": {},
   "source": [
    "I am especially interested in margins and margin changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "whole-supply",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at change in margins over years\n",
    "def calculate_margin_change(df):\n",
    "    row = df.iloc[-1]\n",
    "    data = df\n",
    "#     if df.shape[0] == 1:\n",
    "#         current_id = row[\"id\"]\n",
    "#         # Find intersection of other districts with unique district and mean years not in current data\n",
    "#         overlays = gpd.overlay(margins_election.loc[margins_election.id == current_id], margins_election.loc[(margins_election.id != current_id) & (margins_election.year != row[\"year\"])], how=\"intersection\")\n",
    "#         overlays = overlays.rename(columns={k: k.strip(\"_2\") for k in overlays.columns if \"_2\" in k}).drop(columns=[col for col in overlays.columns if \"_1\" in col]).dropna(how=\"all\", axis=1)\n",
    "#         data = overlays.groupby(\"year\").mean().reset_index().append(row, ignore_index=True)\n",
    "    \n",
    "    for beg, end in [[2012, 2016], [2016, 2020]]:#, [2012, 2020]]:\n",
    "        row_beg = data.loc[data.year == beg]\n",
    "        row_end = data.loc[data.year == end]\n",
    "        if len(row_beg) > 0 and len(row_end) > 0:\n",
    "            df[f\"{end}-{beg}\"] = row_end[\"usprs_margin\"].values[0] - row_beg[\"usprs_margin\"].values[0]\n",
    "    return df\n",
    "g = margins_election.groupby(\"vtdid\").apply(calculate_margin_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bigger-tract",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in g.columns:\n",
    "    try:\n",
    "        g[col] = pd.to_numeric(g[col])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# gpd.GeoDataFrame(g, geometry=\"geom\").to_file(\"FullStateProcessedElections.geojson\", driver='GeoJSON')\n",
    "\n",
    "# gpd.GeoDataFrame(g.loc[g.countyname.isin(counties)], geometry=\"geom\").to_file(\"ProcessedElections.geojson\", driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neural-thailand",
   "metadata": {},
   "source": [
    "# Export to Postgres\n",
    "At this point, I want to save the data back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embedded-springfield",
   "metadata": {},
   "outputs": [],
   "source": [
    "# con = psycopg2.connect(database=\"postgres\", user=\"postgres\", password=os.getenv(\"POSTGRES_PASSWORD\"), host=\"localhost\")\n",
    "# from sqlalchemy import create_engine\n",
    "# engine = create_engine(f\"postgresql+psycopg2://postgres:{os.getenv('POSTGRES_PASSWORD')}@localhost/postgres\")\n",
    "# gpd.GeoDataFrame(g, geometry=\"geom\").to_postgis(\"processed_election\", engine, index=False, if_exists=\"replace\")\n",
    "# con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooperative-preparation",
   "metadata": {},
   "outputs": [],
   "source": [
    "vtd_values = g.loc[(g.year==2020) & (g.usprs_margin.isna())].vtd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "featured-grill",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpd.GeoDataFrame(g.loc[g.year == 2020], geometry=\"geom\").plot(column=\"usprs_margin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerous-package",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data = margins_election[[\"mean_emv\", \"growth\", \"usprs_margin\", \"year\", \"usprstotal\", \"usprs_vote_density\", \"cit_dis\", \"ronehouse\", \"medinc\", \"medage\", \"popdensity\"]], hue='year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civil-addition",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "for year in [2020, 2016, 2012]:\n",
    "    d = margins_election.loc[margins_election[\"year\"] == year].dropna(axis=1, how=\"all\")\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=[15,10])\n",
    "\n",
    "    ax.set_title(year)\n",
    "    sns.scatterplot(\n",
    "        x=\"cit_dis\",\n",
    "        y=\"usprs_margin\",\n",
    "        hue=\"median_emv\",\n",
    "        size=\"growth\",\n",
    "        sizes=(10, 300),\n",
    "        palette=\"viridis\",\n",
    "        linewidth=0,\n",
    "        data=d\n",
    "    )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fancy-conservative",
   "metadata": {},
   "source": [
    "# Voting Patterns in High Growth Areas\n",
    "From the regional parcel data, there is an encoding of `YEAR_BUILT` which would track well with population growth due to new single family housing developments.\n",
    "Again, I wish I had better fidelity on the effects of higher density housing because their are likely patterns there as well due to the growth of high density developments in outer ring suburbs in the Twin Cities metro.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dense-arlington",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at mean of high growth areas over time\n",
    "def group_growth(val, limits=[0.10, 0.20]):\n",
    "    if val >= limits[-1]:\n",
    "        return \"High\"\n",
    "    elif val <= limits[0]:\n",
    "        return \"Low\"\n",
    "    else:\n",
    "        return \"Med\"\n",
    "    \n",
    "margins_election[\"growth_cat\"] = margins_election[\"growth\"].apply(lambda x: group_growth(x))\n",
    "#pd.cut(margins_election[\"growth\"], 3, labels=[\"Low\", \"Med\", \"High\"])\n",
    "margins_election.groupby([\"growth_cat\", \"year\"])[\"usprs_margin\"].describe().dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-auditor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# growth = margins_election.groupby([\"year\", \"growth_cat\"])[\"usprs_margin\"].describe().dropna()\n",
    "# growth\n",
    "sns.boxplot(data=margins_election.loc[margins_election.year.isin(years)], x=\"year\", y=\"usprs_margin\", hue=\"growth_cat\", dodge=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "federal-assist",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=[25, 10])\n",
    "gdf = gpd.GeoDataFrame(margins_election.loc[(margins_election.year == 2020) & (margins_election.countyname.isin(counties))], geometry=\"geom\")\n",
    "gdf.crs = 4326\n",
    "gdf.plot(column=\"growth_cat\", ax=ax[1], legend=True)\n",
    "gdf.plot(column=\"usprs_margin\", ax=ax[0], legend=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "perceived-shark",
   "metadata": {},
   "source": [
    "# Estimated value trends\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "close-anderson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at mean of high growth areas over time\n",
    "margins_election[\"median_emv_cat\"] = pd.cut(margins_election[\"median_emv\"], bins=[0, 150000, 250000, 450000, 600000, np.max(margins_election[\"median_emv\"])])\n",
    "#pd.cut(margins_election[\"growth\"], 3, labels=[\"Low\", \"Med\", \"High\"])\n",
    "margins_election.groupby([\"median_emv_cat\", \"year\"])[\"usprs_margin\"].describe().dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excellent-idaho",
   "metadata": {},
   "outputs": [],
   "source": [
    "# growth = margins_election.groupby([\"year\", \"growth_cat\"])[\"usprs_margin\"].describe().dropna()\n",
    "# growth\n",
    "fig, ax = plt.subplots(figsize=[30,10])\n",
    "sns.boxplot(data=margins_election.loc[margins_election.year.isin(years)], hue=\"year\", y=\"usprs_margin\", x=\"median_emv_cat\", dodge=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-egyptian",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=[25, 10])\n",
    "gdf = gpd.GeoDataFrame(margins_election.loc[(margins_election.year == 2020) & (margins_election.countyname.isin(counties))], geometry=\"geom\")\n",
    "gdf.crs = 4326\n",
    "gdf.plot(column=\"median_emv_cat\", ax=ax[1], legend=True)\n",
    "gdf.plot(column=\"usprs_margin\", ax=ax[0], legend=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infectious-practitioner",
   "metadata": {},
   "source": [
    "# Distance trends\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interim-lodging",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at mean of high growth areas over time\n",
    "margins_election[\"cit_dis_cat\"] = pd.cut(margins_election[\"cit_dis\"], bins=[0, 5, 15, 20, 25, 30, np.max(margins_election[\"cit_dis\"])])\n",
    "#pd.cut(margins_election[\"growth\"], 3, labels=[\"Low\", \"Med\", \"High\"])\n",
    "margins_election.groupby([\"cit_dis_cat\", \"year\"])[\"usprs_margin\"].describe().dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-baptist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# growth = margins_election.groupby([\"year\", \"growth_cat\"])[\"usprs_margin\"].describe().dropna()\n",
    "# growth\n",
    "fig, ax = plt.subplots(figsize=[30,10])\n",
    "sns.boxplot(data=margins_election.loc[margins_election.year.isin(years)], hue=\"year\", y=\"usprs_margin\", x=\"cit_dis_cat\", dodge=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practical-eligibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=[25, 10])\n",
    "gdf = gpd.GeoDataFrame(margins_election.loc[(margins_election.year == 2020) & (margins_election.countyname.isin(counties))], geometry=\"geom\")\n",
    "gdf.crs = 4326\n",
    "gdf.plot(column=\"cit_dis_cat\", ax=ax[1], legend=True)\n",
    "gdf.plot(column=\"usprs_margin\", ax=ax[0], legend=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "general-poison",
   "metadata": {},
   "source": [
    "# Transient 1-4 year in house ratio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-sacramento",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at mean of high growth areas over time\n",
    "margins_election[\"ronehouse_cat\"] = pd.cut(margins_election[\"ronehouse\"], bins=[0, 0.02, 0.04, 0.06, 0.08, 0.10, np.max(margins_election[\"ronehouse\"])])\n",
    "#pd.cut(margins_election[\"growth\"], 3, labels=[\"Low\", \"Med\", \"High\"])\n",
    "# margins_election.groupby([\"ronehouse_cat\", \"year\"])[\"usprs_margin\"].describe().dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conceptual-claim",
   "metadata": {},
   "outputs": [],
   "source": [
    "# growth = margins_election.groupby([\"year\", \"growth_cat\"])[\"usprs_margin\"].describe().dropna()\n",
    "# growth\n",
    "fig, ax = plt.subplots(figsize=[30,10])\n",
    "sns.boxplot(data=margins_election.loc[margins_election.year.isin(years)], hue=\"year\", y=\"usprs_margin\", x=\"ronehouse_cat\", dodge=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "round-console",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=[25, 10])\n",
    "gdf = gpd.GeoDataFrame(margins_election.loc[(margins_election.year == 2020) & (margins_election.countyname.isin(counties))], geometry=\"geom\")\n",
    "gdf.crs = 4326\n",
    "gdf.plot(column=\"ronehouse_cat\", ax=ax[1], legend=True)\n",
    "gdf.plot(column=\"usprs_margin\", ax=ax[0], legend=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-program",
   "metadata": {},
   "source": [
    "# Transient 1-4 year in house ratio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unusual-slovenia",
   "metadata": {},
   "outputs": [],
   "source": [
    "margins_election[\"medage\"].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-laser",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at mean of high growth areas over time\n",
    "margins_election[\"medage_cat\"] = pd.cut(margins_election[\"medage\"], bins=[0, 20, 30, 40, 50, 60, np.max(margins_election[\"medage\"])])\n",
    "#pd.cut(margins_election[\"growth\"], 3, labels=[\"Low\", \"Med\", \"High\"])\n",
    "# margins_election.groupby([\"ronehouse_cat\", \"year\"])[\"usprs_margin\"].describe().dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subsequent-tanzania",
   "metadata": {},
   "outputs": [],
   "source": [
    "# growth = margins_election.groupby([\"year\", \"growth_cat\"])[\"usprs_margin\"].describe().dropna()\n",
    "# growth\n",
    "fig, ax = plt.subplots(figsize=[30,10])\n",
    "sns.boxplot(data=margins_election.loc[margins_election.year.isin(years)], hue=\"year\", y=\"usprs_margin\", x=\"medage_cat\", dodge=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-paradise",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=[25, 10])\n",
    "gdf = gpd.GeoDataFrame(margins_election.loc[(margins_election.year == 2020) & (margins_election.countyname.isin(counties))], geometry=\"geom\")\n",
    "gdf.crs = 4326\n",
    "gdf.plot(column=\"medage_cat\", ax=ax[1], legend=True)\n",
    "gdf.plot(column=\"usprs_margin\", ax=ax[0], legend=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "external-tanzania",
   "metadata": {},
   "source": [
    "# Census Median Income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-adapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "margins_election[\"medinc\"].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-opera",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at mean of high growth areas over time\n",
    "margins_election[\"medinc_cat\"] = pd.cut(margins_election[\"medinc\"], bins=[0, 40000, 60000, 80000, 100000, 120000, 140000, np.max(margins_election[\"medinc\"])])\n",
    "#pd.cut(margins_election[\"growth\"], 3, labels=[\"Low\", \"Med\", \"High\"])\n",
    "# margins_election.groupby([\"ronehouse_cat\", \"year\"])[\"usprs_margin\"].describe().dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medieval-strain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# growth = margins_election.groupby([\"year\", \"growth_cat\"])[\"usprs_margin\"].describe().dropna()\n",
    "# growth\n",
    "fig, ax = plt.subplots(figsize=[30,10])\n",
    "sns.boxplot(data=margins_election.loc[margins_election.year.isin(years)], hue=\"year\", y=\"usprs_margin\", x=\"medinc_cat\", dodge=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "played-maria",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=[25, 10])\n",
    "gdf = gpd.GeoDataFrame(margins_election.loc[(margins_election.year == 2020) & (margins_election.countyname.isin(counties))], geometry=\"geom\")\n",
    "gdf.crs = 4326\n",
    "gdf.plot(column=\"medinc_cat\", ax=ax[1], legend=True)\n",
    "gdf.plot(column=\"usprs_margin\", ax=ax[0], legend=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "purple-fluid",
   "metadata": {},
   "outputs": [],
   "source": [
    "margin_cols = [col for col in g.columns if \"-20\" in col]\n",
    "id_cols = [col for col in g.columns if \"-20\" not in col]\n",
    "margin_change = g.melt(id_vars=id_cols, value_vars = margin_cols, var_name=\"timeframe\", value_name=\"margin_change\")\n",
    "margin_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similar-frontier",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=[15,10])\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=\"median_emv\",\n",
    "    y=\"margin_change\",\n",
    "    size=\"growth\",\n",
    "    hue=\"timeframe\",\n",
    "#         palette=\"ch:r=-.2,d=.3_r\",\n",
    "    ax=ax,\n",
    "    linewidth=0,\n",
    "    data=margin_change\n",
    ")\n",
    "# sns.scatterplot(\n",
    "#     x=\"median_emv\",\n",
    "#     y=\"usprsdfl\",\n",
    "#     size=\"growth\",\n",
    "#     hue=\"timeframe\",\n",
    "# #         palette=\"ch:r=-.2,d=.3_r\",\n",
    "#     ax=ax2,\n",
    "#     linewidth=0,\n",
    "#     data=margin_change.loc[margin_change.year.isin([2012,2016,2020])]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preliminary-wrestling",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "sound-upper",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple-butter",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "# X_cols = [\"median_emv\", \"median_age\", \"growth\", \"cit_dis\", \"usprs_vote_density\"]\n",
    "X_cols = [\"cit_dis\", \"growth\", \"usprs_vote_density\", \"mean_emv\", \"mean_age\", \"medage\", \"medinc\", \"ronehouse\"]\n",
    "Y_cols = [\"margin_change\"]\n",
    "# There is one that has a zero value\n",
    "\n",
    "year_mask = (margin_change.timeframe == \"2020-2016\") & (margin_change.countyname.isin(counties))\n",
    "input_data = margin_change.loc[year_mask]\n",
    "input_data=input_data.loc[input_data[\"median_emv\"] != 0]\n",
    "input_data = input_data.loc[~input_data[X_cols+Y_cols].isna().any(axis=1)]\n",
    "pipe = make_pipeline(StandardScaler(), RandomForestClassifier(n_estimators=100))\n",
    "X = input_data[X_cols].astype(float)\n",
    "Y = np.squeeze((input_data[Y_cols] > 0).values.astype(int))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y)\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superb-hobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib import cm\n",
    "gdf = gpd.GeoDataFrame(input_data.loc[(input_data.year == 2020) & (input_data.countyname.isin(counties))], geometry=\"geom\")\n",
    "gdf[\"Increase\"] = (gdf[\"margin_change\"] > 0).values.astype(int)\n",
    "top = cm.get_cmap('Reds', 128)\n",
    "bottom = cm.get_cmap('Blues', 128)\n",
    "newcolors = np.vstack((top(0),\n",
    "                       bottom(0)))\n",
    "newcmp = ListedColormap(newcolors, name='RedBlue')\n",
    "fig, ax = plt.subplots()\n",
    "gdf.plot(column=\"Increase\", ax=ax, legend=True, cmap=\"RdBu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multiple-cruise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# True Positives\n",
    "mask = y_test == 1\n",
    "pos_correct = np.sum(y_pred[mask] == 1)\n",
    "print(f\"True positive accuracy = {np.round(pos_correct / np.sum(mask),3)}\")\n",
    "mask = y_test == 1\n",
    "pos_false = np.sum(y_pred[mask] == 0)\n",
    "print(f\"False positive accuracy = {np.round(pos_false / np.sum(mask),3)}\")\n",
    "mask = y_test == 0\n",
    "neg_true = np.sum(y_pred[mask] == 0)\n",
    "print(f\"True negative accuracy = {neg_true / np.sum(mask)}\")\n",
    "mask = y_test == 0\n",
    "neg_false = np.sum(y_pred[mask] == 1)\n",
    "print(f\"True negative accuracy = {neg_false / np.sum(mask)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welsh-ideal",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assured-impact",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(list(X_test.columns), clf.feature_importances_, \"o\", ms=10)\n",
    "ax.set_xlabel(\"Feature\")\n",
    "ax.set_ylabel(\"Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fleet-pantyhose",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pred = pipe.predict(gdf[X_cols].astype(float))\n",
    "gdf[\"prediction\"] = full_pred == gdf[\"Increase\"]\n",
    "fig, ax = plt.subplots()\n",
    "gdf.plot(column=\"prediction\", ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-power",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(pipe, open(\"pickle_models/random_forest.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriental-denver",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.loc[gdf[\"prediction\"] == 0][[\"margin_change\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dietary-notebook",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "## PLS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "casual-moment",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "# X_cols = [\"median_emv\", \"median_age\", \"growth\", \"cit_dis\", \"usprs_vote_density\"]\n",
    "X_cols = [\"cit_dis\", \"growth\", \"usprs_vote_density\", \"median_emv\", \"median_age\", \"medage\", \"medinc\", \"ronehouse\"]\n",
    "Y_cols = [\"margin_change\"]\n",
    "# There is one that has a zero value\n",
    "\n",
    "year_mask = (margin_change.timeframe == \"2020-2016\") & (margin_change.countyname.isin(counties))\n",
    "input_data = margin_change.loc[year_mask]\n",
    "input_data=input_data.loc[input_data[\"median_emv\"] != 0]\n",
    "input_data = input_data.loc[~input_data[X_cols+Y_cols].isna().any(axis=1)]\n",
    "X = (input_data[X_cols] - input_data[X_cols].mean())/input_data[X_cols].std()\n",
    "Y = input_data[Y_cols]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-clark",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pls = PLSRegression(n_components=4)\n",
    "pls.fit(X_train, y_train)\n",
    "y_pred = pls.predict(X_test)\n",
    "fig, [ax, ax2] = plt.subplots(1,2, figsize=[25,10])\n",
    "# pred_data = pd.concat([X_test, y_test, pd.Series(np.squeeze(y_pred), name=\"predict\")], ignore_index=True)\n",
    "# pred_data\n",
    "sns.scatterplot(\n",
    "        x=y_test[\"margin_change\"],\n",
    "        y=np.squeeze(y_pred),\n",
    "        hue=X_test[\"median_emv\"],\n",
    "        size=X_test[\"growth\"],\n",
    "        sizes=(10, 300),\n",
    "        palette=\"viridis\",\n",
    "        linewidth=0,\n",
    "#         data=pred_data\n",
    "    ax=ax\n",
    "    )\n",
    "# sns.scatterplot(x=y_test, y=pls.predict(X_test), hue=\"\")\n",
    "sns.histplot(y_test[\"margin_change\"].values - np.squeeze(y_pred), ax=ax2)\n",
    "# sns.scatterplot(\n",
    "#         x=y_test[\"usprs_margin\"],\n",
    "#         y=y_test[\"usprs_margin\"].values - np.squeeze(y_pred),\n",
    "# #         hue=X_test[\"median_emv\"],\n",
    "# #         size=X_test[\"growth\"],\n",
    "#         sizes=(10, 300),\n",
    "#         palette=\"viridis\",\n",
    "#         linewidth=0,\n",
    "# #         data=pred_data\n",
    "#     ax=ax2\n",
    "#     )\n",
    "# ax2.plot(y_test - y_pred, \"o\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "established-casino",
   "metadata": {},
   "source": [
    "# Train Keras model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-burke",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_cols = [\"cit_dis\", \"growth\", \"usprs_vote_density\", \"median_emv\", \"median_age\", \"medage\", \"medinc\", \"ronehouse\"]\n",
    "Y_cols = [\"margin_change\"]\n",
    "# There is one that has a zero value\n",
    "\n",
    "\n",
    "year_mask = (margin_change.year == 2020) & (margin_change.timeframe == \"2020-2016\") & (margin_change[\"margin_change\"].notna())\n",
    "input_data = margin_change.loc[year_mask]\n",
    "input_data=input_data.loc[input_data[\"median_emv\"] != 0]\n",
    "input_data = input_data.loc[~input_data[X_cols+Y_cols].isna().any(axis=1)]\n",
    "\n",
    "# X = (input_data[X_cols] - input_data[X_cols].mean())/input_data[X_cols].std()\n",
    "X = input_data[X_cols]\n",
    "Y = input_data[Y_cols]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X_train.values.astype(float), y_train.values.astype(float)))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test.values.astype(float), y_test.values.astype(float)))\n",
    "train_dataset = dataset.shuffle(len(input_data)).batch(1)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, Y)\n",
    "\n",
    "# model = tf.keras.Sequential([\n",
    "#   tf.keras.layers.LayerNormalization(),\n",
    "#   tf.keras.layers.Dense(16, input_shape=(len(X_cols),)),\n",
    "#   tf.keras.layers.Dense(32, activation='relu'),\n",
    "#   tf.keras.layers.Dense(32, activation='relu'),\n",
    "#   tf.keras.layers.Dense(1)\n",
    "# ])\n",
    "\n",
    "# model.compile(\n",
    "#     optimizer='adam',\n",
    "#     loss=tf.keras.losses.MeanSquaredError(),\n",
    "#     metrics=[\n",
    "#         tf.keras.metrics.MeanSquaredError(),\n",
    "#     ]\n",
    "# )\n",
    "# model.fit(train_dataset, epochs=2000, verbose=0, validation_data=(X_test.values.astype(np.float), y_test.values.astype(np.float)), use_multiprocessing=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romantic-nitrogen",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "def build_model(hp):\n",
    "    model = tf.keras.Sequential([\n",
    "      tf.keras.layers.LayerNormalization(),\n",
    "      tf.keras.layers.Dense(16, input_shape=(len(X_cols),)),\n",
    "    ])\n",
    "    for i in range(hp.Int('num_layers', 2, 10)):\n",
    "        model.add(tf.keras.layers.Dense(units=hp.Int('units_' + str(i),\n",
    "                                            min_value=32,\n",
    "                                            max_value=512,\n",
    "                                            step=32),\n",
    "                               activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(\n",
    "            hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
    "        loss=tf.keras.losses.MeanSquaredError(),\n",
    "        metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "    return model\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='mean_squared_error',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=3,\n",
    "    directory='logs',\n",
    "    project_name='mnelectionmean'\n",
    ")\n",
    "tuner.search_space_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rational-possession",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(train_dataset,\n",
    "             epochs=5,\n",
    "             validation_data=(X_test.values.astype(float), y_test.values.astype(float)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attended-torture",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modular-camel",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_dataset, epochs=2000, verbose=0, validation_data=(X_test.values.astype(float), y_test.values.astype(float)), use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stunning-appliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"CurrentFitMeanOnly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mexican-dryer",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions = model(X.values.astype(np.float)).numpy()\n",
    "d = plt.hist(Y.values - predictions, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corrected-resistance",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.GeoDataFrame(input_data, geometry=\"geom\")\n",
    "gdf[\"predict\"] = predictions.astype(np.float)\n",
    "gdf[\"predict_resd\"] = (Y.values - predictions).astype(np.float)\n",
    "gdf.plot(column=\"predict_resd\", legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scheduled-campus",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf[[\"margin_change\", \"predict_resd\"]].plot.scatter(x=\"margin_change\", y=\"predict_resd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marked-bishop",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(gdf.sort_values(\"predict_resd\")[X_cols + [\"predict_resd\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "packed-norman",
   "metadata": {},
   "source": [
    "# Model Explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moderate-butler",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf[[\"mean_age\", \"mean_emv\", \"cit_dis\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sapphire-durham",
   "metadata": {},
   "outputs": [],
   "source": [
    "(gdf.mean_age >= 0.8 * 1975) & (gdf.mean_age <= 1.5 * 1975)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "according-charity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_matches(mean_age, mean_emv, cit_dis):\n",
    "    age_mask = (gdf.mean_age >= .8 * mean_age) & (gdf.mean_age <= 1.2 * mean_age)\n",
    "    emv_mask = (gdf.mean_emv >= .8 * mean_emv) & (gdf.mean_emv <= 1.2 * mean_emv)\n",
    "    cit_mask = (gdf.cit_dis >= .8 * cit_dis) & (gdf.cit_dis <= 1.2 * cit_dis)\n",
    "    return gdf.loc[(age_mask & emv_mask & cit_mask)]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laden-terminology",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_closest_matches(1999, 450000, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continent-shelf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
